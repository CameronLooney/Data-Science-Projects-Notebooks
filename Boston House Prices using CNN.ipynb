{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boston Housing Prices Predicition using CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a regression problem which consists of predicting a continuous\n",
    "value instead instead of a discrete label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johnl\\Anaconda\\lib\\site-packages\\requests\\__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.4) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import boston_housing\n",
    "(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features\n",
    "1. Per capita crime rate.\n",
    "2. Proportion of residential land zoned for lots over 25,000 square feet\n",
    "3. Proportion of non-retail business acres per town.\n",
    "4. Charles River dummy variable (= 1 if tract bounds river; 0 otherwise).\n",
    "5. Nitric oxides concentration (parts per 10 million).\n",
    "6. Average number of rooms per dwelling.\n",
    "7. Proportion of owner-occupied units built prior to 1940.\n",
    "8. Weighted distances to five Boston employment centres.\n",
    "9. Index of accessibility to radial highways.\n",
    "10. Full-value property-tax rate per 10,000 dollars\n",
    "11. Pupil-teacher ratio by town.\n",
    "12. 1000 * (Bk - 0.63) ** 2 where Bk is the proportion of Black people by town.\n",
    "13. % lower status of the population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the ranges arent the same across all data it would make feeding into the neural network and getting a good result difficult. <br>\n",
    "The normal practice for this is feature-wise normalization <br>\n",
    "Normalization is a scaling technique in which values are shifted and rescaled so that they end up ranging between 0 and 1. It is also known as Min-Max scaling. <br>\n",
    "We will apply this technique to each feature as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We will subtract the mean of the feature and divide by the standard deviation \n",
    "\n",
    "- Thus the feature will be centered around 0 and will have a unit standard deviation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = train_data.mean(axis=0)\n",
    "train_data -= mean\n",
    "std = train_data.std(axis=0)\n",
    "train_data /= std\n",
    "test_data -= mean\n",
    "test_data /= std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the quantities that we use for normalizing the test data have been computed using the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we will need to instantiate the same model multiple times we are going to make the model as a function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(64, activation='relu',\n",
    "                           input_shape=(train_data.shape[1],)))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function (mse = Mean Squared Error)\n",
    "In MSE, we calculate the square of our error and then take it’s mean. This is a quadratic scoring method, meaning, the penalty is proportional to not the error (like in MAE), but to the square of the error, which gives relatively higher weight (penalty) to large errors/outliers, while smoothening the gradient for smaller errors.<br>\n",
    "- **Advantages**:<br>\n",
    "    1. For small errors, MSE helps converge to the minima efficiently, as the gradient reduces gradually.\n",
    "- **Disadvantages**:<br>\n",
    "    1. Squaring the values does increases the rate of training, but at the same time, an extremely large loss may lead to a drastic jump during backpropagation, which is not desirable.\n",
    "    2. MSE is also sensitive to outliers, i.e. outliers in data may impact our network more, as the loss for these will be considerably higher.\n",
    "    \n",
    "### Metric (mae = Mean Absolute Error)\n",
    "MAE is the simplest error function, it literally just calculates the absolute difference (discards the sign) between the actual and predicted values and takes it’s mean.\n",
    "- **Advantages:** <br>\n",
    "    1. MAE is the simplest method to calculate the loss.\n",
    "    2. Due to its simplicity, it is computationally inexpensive.\n",
    "- **Disadvantages:** <br>\n",
    "    1. MAE calculates loss by considering all the errors on the same scale. For example, if one of the output is on the scale of hundred while other is on the scale of thousand, our network won’t be able to distinguish between them just based on MAE, and so, it’s hard to alter weights during backpropagation.\n",
    "    2. MAE is a linear scoring method, i.e. all the errors are weighted equally while calculating the mean. This means that while backpropagation, we may just jump past the minima due to MAE’s steep nature.\n",
    "    \n",
    "### Lack of Activation ? \n",
    "Our network ends with a single unit, and no activation (i.e. it will be linear layer). <br>\n",
    "This is a typical setup for scalar regression (i.e. regression where we are trying to predict a single continuous value).<br>\n",
    "Applying an activation function would constrain the range that the output can take.<br>\n",
    "For instance if we applied a activation function to our sigmoid last layer, the network could only learn to predict values between 0 and 1. <br>\n",
    "Because the last layer is purely linear, the network is free to learn to predict values in any range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation \n",
    "due to our limited sample size we are going to implement cross validation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-Fold Cross-Validation\n",
    "Cross-validation is a resampling procedure used to evaluate machine learning models on a limited data sample. <br>\n",
    "\n",
    "The procedure has a single parameter called k that refers to the number of groups that a given data sample is to be split into. As such, the procedure is often called k-fold cross-validation. When a specific value for k is chosen, it may be used in place of k in the reference to the model, such as k=10 becoming 10-fold cross-validation.\n",
    "\n",
    "Cross-validation is primarily used to estimate the skill of a machine learning model on unseen data. That is, to use a limited sample in order to estimate how the model is expected to perform in general when used to make predictions on data not used during the training of the model.\n",
    "\n",
    "It is a popular method because it is simple to understand and because it generally results in a less biased or less optimistic estimate of the model skill than other methods, such as a simple train/test split.\n",
    "\n",
    "#### Precedure Outline\n",
    "1. shuffle our data set randomly (think deck of cards)\n",
    "2. split the dataset into k groups\n",
    "3. For each group: \n",
    "    - Take one group as our test data \n",
    "    - Take the remaining (K-1) groups as training data\n",
    "    - Fit our model on training data and evaluate it on the test data\n",
    "    - Save the evaluation and get rid of the model\n",
    "4. We can see how well our model performs using the evaluation scores\n",
    "\n",
    "#### Choosing a k value\n",
    "So how do we choose what k will be?\n",
    "\n",
    "Common Method for Choosing your k value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K- fold Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold # 0\n",
      "Train on 303 samples, validate on 101 samples\n",
      "Epoch 1/3\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 16.3744 - mae: 2.7015 - val_loss: 13.8956 - val_mae: 2.4337\n",
      "Epoch 2/3\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 15.2265 - mae: 2.6427 - val_loss: 13.3182 - val_mae: 2.3435\n",
      "Epoch 3/3\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 14.5815 - mae: 2.5744 - val_loss: 12.6337 - val_mae: 2.3067\n",
      "processing fold # 1\n",
      "Train on 303 samples, validate on 101 samples\n",
      "Epoch 1/3\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 16.5608 - mae: 2.6931 - val_loss: 13.7641 - val_mae: 2.7327\n",
      "Epoch 2/3\n",
      "303/303 [==============================] - 0s 2ms/step - loss: 15.0246 - mae: 2.5408 - val_loss: 14.1897 - val_mae: 2.8479\n",
      "Epoch 3/3\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 13.6494 - mae: 2.4474 - val_loss: 12.2773 - val_mae: 2.6447\n",
      "processing fold # 2\n",
      "Train on 303 samples, validate on 101 samples\n",
      "Epoch 1/3\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 15.5377 - mae: 2.7133 - val_loss: 18.1728 - val_mae: 2.6596\n",
      "Epoch 2/3\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 13.8335 - mae: 2.5664 - val_loss: 18.7929 - val_mae: 2.9044\n",
      "Epoch 3/3\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 11.9574 - mae: 2.4794 - val_loss: 17.3564 - val_mae: 2.7074\n",
      "processing fold # 3\n",
      "Train on 303 samples, validate on 101 samples\n",
      "Epoch 1/3\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 19.3915 - mae: 2.7711 - val_loss: 31.9644 - val_mae: 3.4101\n",
      "Epoch 2/3\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 15.9278 - mae: 2.5059 - val_loss: 32.4552 - val_mae: 3.5046\n",
      "Epoch 3/3\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 15.4423 - mae: 2.4378 - val_loss: 26.3080 - val_mae: 3.0693\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "k = 4\n",
    "num_val_samples = len(train_data) // k\n",
    "num_epochs = 100\n",
    "all_scores = []\n",
    "all_mae_histories = []\n",
    "for i in range(k):\n",
    "    print('processing fold #', i)\n",
    "    # Prepare the validation data: data from partition # k\n",
    "    val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    # Prepare the training data: data from all other partitions\n",
    "    partial_train_data = np.concatenate([train_data[:i * num_val_samples],train_data[(i + 1) * num_val_samples:]],axis=0)\n",
    "    partial_train_targets = np.concatenate([train_targets[:i * num_val_samples],train_targets[(i + 1) * num_val_samples:]],axis=0)\n",
    "    # Build the Keras model (already compiled)\n",
    "    model= build_model()\n",
    "    # Train the model (in silent mode, verbose=0)\n",
    "    model.fit(partial_train_data, partial_train_targets,epochs=num_epochs, batch_size=1, verbose=0)\n",
    "    # Evaluate the model on the validation data\n",
    "    # Train the model (in silent mode, verbose=0)\n",
    "    history = model.fit(partial_train_data, partial_train_targets,validation_data=(val_data, val_targets),\n",
    "                        epochs=num_epochs, batch_size=1, verbose=1)\n",
    "    mae_history = history.history['val_mae']\n",
    "    all_mae_histories.append(mae_history)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2.433706045150757, 2.343496084213257, 2.3067471981048584],\n",
       " [2.7326672077178955, 2.8479158878326416, 2.64471435546875],\n",
       " [2.6596012115478516, 2.9044253826141357, 2.7074146270751953],\n",
       " [3.410062551498413, 3.504591464996338, 3.06933856010437]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_mae_histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.8090092539787292, 2.900107204914093, 2.6820536851882935]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_mae_history = [np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]\n",
    "average_mae_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Get a fresh, compiled model.\n",
    "model = build_model()\n",
    "# Train it on the entirety of the data.\n",
    "model.fit(train_data, train_targets,\n",
    " epochs=80, batch_size=16, verbose=0)\n",
    "test_mse_score, test_mae_score = model.evaluate(test_data, test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.802682399749756"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mae_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction is still off but more accurate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion and takeways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We have a varity of loss functions to use in regression which are different to the ones used for classification \n",
    "- When features in the input data have values in different ranges, each feature should be scaled independently as a preprocessing step.\n",
    "- When there is little data available, using K-Fold validation is a great way to reliably evaluate a model.\n",
    "- When little training data is available, it is preferable to use a small network with very few hidden layers (typically only one or two), in order to avoid severe overfitting\n",
    "\n",
    "### Loss Functions for Regression \n",
    "\n",
    "- #### Mean Squared Error Loss L2\n",
    "    - The Mean Squared Error, or MSE, loss is the default loss to use for regression problems.\n",
    "    - It is the loss function to be evaluated first and only changed if you have a good reason.\n",
    "    - Mean squared error is calculated as the average of the squared differences between the predicted and actual values. The result is always positive regardless of the sign of the predicted and actual values and a perfect value is 0.0. The squaring means that larger mistakes result in more error than smaller mistakes, meaning that the model is punished for making larger mistakes.\n",
    "    - The mean squared error loss function can be used in Keras by specifying ‘mse‘ or ‘mean_squared_error‘ as the loss function when compiling the model.\n",
    "    - It is recommended that the output layer has one node for the target variable and the linear activation function is used.\n",
    "    - model.add(Dense(1, activation='linear'))\n",
    "\n",
    "- #### Mean Squared Logarithmic Error Loss\n",
    "    - There may be regression problems in which the target value has a spread of values and when predicting a large value, you may not want to punish a model as heavily as mean squared error.\n",
    "    - Instead, you can first calculate the natural logarithm of each of the predicted values, then calculate the mean squared error. This is called the Mean Squared Logarithmic Error loss, or MSLE for short.\n",
    "    - It has the effect of relaxing the punishing effect of large differences in large predicted values.\n",
    "    - As a loss measure, it may be more appropriate when the model is predicting unscaled quantities directly.\n",
    "    - The model can be updated to use the ‘mean_squared_logarithmic_error‘ loss function and keep the same configuration for the output layer.\n",
    "\n",
    "- #### Mean Absolute Error Loss L1\n",
    "    - On some regression problems, the distribution of the target variable may be mostly Gaussian, but may have outliers, e.g. large or small values far from the mean value.\n",
    "    - The Mean Absolute Error, or MAE, loss is an appropriate loss function in this case as it is more robust to outliers. It is calculated as the average of the absolute difference between the actual and predicted values.\n",
    "    - The model can be updated to use the ‘mean_absolute_error‘ loss function and keep the same configuration for the output layer.\n",
    "\n",
    "    #### Huber Loss\n",
    "    A comparison between L1 and L2 loss yields the following results:\n",
    "    1. L1 loss is more robust than its counterpart. <br>\n",
    "\n",
    "    On taking a closer look at the formulas, one can observe that if the difference between the predicted and the actual value is high, L2 loss magnifies the effect when compared to L1. Since L2 succumbs to outliers, L1 loss function is the more robust loss function.\n",
    "\n",
    "    2. L1 loss is less stable than L2 loss. <br>\n",
    "\n",
    "    Since L1 loss deals with the difference in distances, a small horizontal change can lead to the regression line jumping a large amount. Such an effect taking place across multiple iterations would lead to a significant change in the slope between iterations.\n",
    "\n",
    "    On the other hand, MSE ensures the regression line moves lightly for a small adjustment in the data point.\n",
    "\n",
    "    Huber Loss combines the robustness of L1 with the stability of L2, essentially the best of L1 and L2 losses. For huge errors, it is linear and for small errors, it is quadratic in nature.\n",
    "\n",
    "\n",
    "###  Evaluation Metrics for Regression\n",
    "\n",
    "- #### M.A.E (Mean Absolute Error)\n",
    "    - It is the simplest & very widely used evaluation technique. <br>\n",
    "    - It is simply the mean of difference b/w actual & predicted values.  <br>\n",
    "- #### M.S.E (Mean Squared Error)\n",
    "    - Another evaluation technique is the Mean Squared Error.  <br>\n",
    "    - It takes the average of the square of the error. <br>\n",
    "    - Here, the error is the difference b/w actual & predicted values. <br>\n",
    "- #### R.M.S.E (Root Mean Squared Error)\n",
    "    - Root mean squared Error is another technique. <br>\n",
    "    - It solves the problem in the above technique. <br>\n",
    "    - It squares the error & then it takes the square root of the total average function. <br>\n",
    "- #### R.M.S.L.E (Root Mean Squared Log Error)\n",
    "    - In case of RMSLE, you take the log of the predictions and actual values.  <br>\n",
    "- #### R — Squared\n",
    "    - Now, we come to another technique called R — Squared, whose actual name is Relative Squared Error. <br>\n",
    "    - This method helps us to calculate the relative error. This technique helps us to judge, which algorithm is better based on their mean squared errors. <br>\n",
    "    - If x >1, this means that, the MSE of the numerator is greater than the MSE of the baseline model which in turn means that, the new model is worse than the baseline model. <br>\n",
    "    - Higher is the R — Squared, better is the model. <br>\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
