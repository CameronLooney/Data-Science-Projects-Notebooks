{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dog vs Cat Classification using CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a CNN?\n",
    "A Convolutional Neural Network (ConvNet/CNN) is a Deep Learning algorithm which can take in an input image, assign importance (learnable weights and biases) to various aspects/objects in the image and be able to differentiate one from the other. \n",
    "## What is the role of a CNN?\n",
    "The role of the ConvNet is to reduce the images into a form which is easier to process, without losing features which are critical for getting a good prediction.\n",
    "## Difference between a CNN and a normal neural network?\n",
    "The CNN makes the explicit assumption that the inputs are images, which allows us to encode certain properties into the architecture. These then make the forward function more efficient to implement and vastly reduce the amount of parameters in the network.\n",
    "## Building a CNN \n",
    "In addition to regular layers used in normal neural network stacks a CNN uses additional layers such as Conv2D, MaxPooling2D.\n",
    "\n",
    "A CNN takes as input tensors of shape (image_height, image_width, image_channels) note this is not including our batch dimension. \n",
    "\n",
    "The image height and width are fairly self explanatory=, however **what is the channel of an image?** <br>\n",
    "The channel is also known as the depth of the image. So for example the channel or depth for an RBG image would be 3 (red, blue and green) a black and white image would have dimension 1, Thr grayness of an image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "import os, shutil\n",
    "# The path to the directory where the original\n",
    "# dataset was uncompressed\n",
    "#original_dataset_dir = r'C:\\Users\\johnl\\Documents\\dogs-vs-cats'\n",
    "# The directory where we will\n",
    "# store our smaller dataset\n",
    "#base_dir = r'C:\\Users\\johnl\\Documents\\dogs-vs-cats_small'\n",
    "#os.mkdir(base_dir)\n",
    "# Directories for our training,\n",
    "# validation and test splits\n",
    "#train_dir = os.path.join(base_dir, 'train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = os.listdir(r'C:\\Users\\johnl\\Documents\\dogs-vs-cats\\train\\train')\n",
    "categories = []\n",
    "for filename in filenames:\n",
    "    category = filename.split('.')[0]\n",
    "    print(category)\n",
    "    if category == 'dog':\n",
    "        categories.append(1)\n",
    "    else:\n",
    "        categories.append(0)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'filename': filenames,\n",
    "    'category': categories\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "df['category'].value_counts().plot.bar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image = load_img(r'C:\\Users\\johnl\\Documents\\dogs-vs-cats\\train\\train\\cat.1.jpg')\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models \n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    " input_shape=(150, 150, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    " optimizer=optimizers.RMSprop(lr=1e-4),\n",
    " metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "model.compile(loss='binary_crossentropy',\n",
    " optimizer='rmsprop',\n",
    " metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Validation Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"category\"] = df[\"category\"].replace({0: 'cat', 1: 'dog'}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, validate_df = train_test_split(df, test_size=0.20, random_state=42)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "validate_df = validate_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_train = train_df.shape[0]\n",
    "total_validate = validate_df.shape[0]\n",
    "batch_size=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    rescale=1./255,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range=0.15,\n",
    "    height_shift_range=0.15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_df, \"C:\\\\Users\\\\johnl\\\\Documents\\\\dogs-vs-cats\\\\train\\\\train\\\\\" ,\n",
    "    target_size=(150,150),\n",
    "    class_mode='binary',\n",
    "    y_col = 'category',\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = validation_datagen.flow_from_dataframe(\n",
    "    validate_df, \"C:\\\\Users\\\\johnl\\\\Documents\\\\dogs-vs-cats\\\\train\\\\train\\\\\" ,\n",
    "    target_size=(150,150),\n",
    "    class_mode='binary',\n",
    "    y_col = 'category',\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    " train_generator,\n",
    " steps_per_epoch=100,\n",
    " epochs=30,\n",
    " validation_data=validation_generator,\n",
    " validation_steps=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Pre-Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using VGG16 model\n",
    "#### Arguments passed to model \n",
    "- **weights**: to specify which weight checkpoint to initialize the model from\n",
    "- **include_top**: meaning do we want to include the densely connected classifer, we dont as we are doing our own binary classification.\n",
    "- **input_shape**: the shape of the image tensors that we will feed to the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    "conv_base = VGG16(weights='imagenet',\n",
    " include_top=False,\n",
    " input_shape=(150, 150, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    " optimizer=optimizers.RMSprop(lr=2e-5),\n",
    " metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    " train_generator,\n",
    " steps_per_epoch=100,\n",
    " epochs=30,\n",
    " validation_data=validation_generator,\n",
    " validation_steps=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
